"use strict";(self.webpackChunkbook=self.webpackChunkbook||[]).push([[8350],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>g});var o=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},i=Object.keys(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=o.createContext({}),m=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=m(e.components);return o.createElement(l.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},p=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=m(n),p=a,g=c["".concat(l,".").concat(p)]||c[p]||u[p]||i;return n?o.createElement(g,r(r({ref:t},d),{},{components:n})):o.createElement(g,r({ref:t},d))}));function g(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,r=new Array(i);r[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:a,r[1]=s;for(var m=2;m<i;m++)r[m]=n[m];return o.createElement.apply(null,r)}return o.createElement.apply(null,n)}p.displayName="MDXCreateElement"},3217:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>i,metadata:()=>s,toc:()=>m});var o=n(7462),a=(n(7294),n(3905));const i={sidebar_position:1},r="10.1 Embed WasmEdge into your Go Host Applications",s={unversionedId:"embed/use-case/yomo",id:"embed/use-case/yomo",title:"10.1 Embed WasmEdge into your Go Host Applications",description:"The following example shows how to embed WasmEdge into a Golang application and then use WasmEdge to do AI inference.",source:"@site/docs/embed/use-case/yomo.md",sourceDirName:"embed/use-case",slug:"/embed/use-case/yomo",permalink:"/book/embed/use-case/yomo",draft:!1,editUrl:"https://github.com/alabulei1/book/docs/embed/use-case/yomo.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"embedSidebar",previous:{title:"WasmEdge Use Cases",permalink:"/book/category/wasmedge-use-cases"},next:{title:"10.2 Embed WasmEdge into your Rust Host Applications",permalink:"/book/embed/use-case/runwasi"}},l={},m=[{value:"Prerequisite",id:"prerequisite",level:2},{value:"The image classification function",id:"the-image-classification-function",level:2},{value:"Integration with YoMo",id:"integration-with-yomo",level:2},{value:"In action",id:"in-action",level:2},{value:"What&#39;s next",id:"whats-next",level:2}],d={toc:m};function c(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,o.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"101-embed-wasmedge-into-your-go-host-applications"},"10.1 Embed WasmEdge into your Go Host Applications"),(0,a.kt)("p",null,"The following example shows how to embed WasmEdge into a Golang application and then use WasmEdge to do AI inference."),(0,a.kt)("hr",null),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://yomo.run/"},"YoMo"),' is a programming framework enabling developers to build a distributed cloud system (Geo-Distributed Cloud System). YoMo\'s communication layer is made on top of the QUIC protocol, which brings high-speed data transmission. In addition, it has a built-in Streaming Serverless "streaming function", which significantly improves the development experience of distributed cloud systems. The distributed cloud system built by YoMo provides an ultra-high-speed communication mechanism between near-field computing power and terminals. It has a wide range of use cases in Metaverse, VR/AR, IoT, etc.'),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"YoMo is written in the Go language. For streaming Serverless, Golang plugins and shared libraries are used to load users' code dynamically, which also have certain limitations for developers. Coupled with Serverless architecture's rigid demand for isolation, this makes WebAssembly an excellent choice for running user-defined functions.")),(0,a.kt)("p",null,"For example, in the process of real-time AI inference in AR/VR devices or smart factories, the camera sends real-time unstructured data to the computing node in the near-field MEC (multi-access edge computing) device through YoMo.  YoMo sends the AI computing result to the end device in real-time when the AI inference is completed. Thus, the hosted AI inference function will be automatically executed.  "),(0,a.kt)("p",null,"However, a challenge for YoMo is to incorporate and manage handler functions written by multiple outside developers in an edge computing node. It requires runtime isolation for those functions without sacrificing performance. Traditional software container solutions, such as Docker, are not up to the task. They are too heavy and slow to handle real-time tasks."),(0,a.kt)("p",null,"WebAssembly provides a lightweight and high-performance software container. It is ideally suited as a runtime for YoMo\u2019s data processing handler functions."),(0,a.kt)("p",null,"In this article, we will show you how to create a Rust function for Tensorflow-based image classification, compile it into WebAssembly, and then use YoMo to run it as a stream data handler. We use ",(0,a.kt)("a",{parentName:"p",href:"https://wasmedge.org/"},"WasmEdge")," as our WebAssembly runtime because it offers the highest performance and flexibility compared with other WebAssembly runtimes. It is the only WebAssembly VM that reliably supports Tensorflow. YoMo manages WasmEdge VM instances and the contained WebAssembly bytecode apps through ",(0,a.kt)("a",{parentName:"p",href:"https://pkg.go.dev/github.com/second-state/WasmEdge-go/wasmedge"},"WasmEdge\u2019s Golang API"),"."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Source code: ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/yomorun/yomo-wasmedge-tensorflow"},"https://github.com/yomorun/yomo-wasmedge-tensorflow"))),(0,a.kt)("p",null,"Checkout ",(0,a.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=E0ltsn6cLIU"},"the WasmEdge image classification function in action in YoMo")),(0,a.kt)("h2",{id:"prerequisite"},"Prerequisite"),(0,a.kt)("p",null,"Obviously, you will need to have ",(0,a.kt)("a",{parentName:"p",href:"https://golang.org/doc/install"},"Golang installed"),", but I will assume you already did."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Golang version should be newer than 1.15 for our example to work.")),(0,a.kt)("p",null,"You also need to install the YoMo CLI application. It orchestrates and coordinates data streaming and handler function invocations."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"$ go install github.com/yomorun/cli/yomo@latest\n$ yomo version\nYoMo CLI version: v0.1.3\n")),(0,a.kt)("p",null,"Next, please install the WasmEdge and its Tensorflow shared libraries. ",(0,a.kt)("a",{parentName:"p",href:"https://wasmedge.org/"},"WasmEdge")," is a leading WebAssembly runtime hosted by the CNCF. We will use it to embed and run WebAssembly programs from YoMo."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install.sh | bash\n")),(0,a.kt)("p",null,"Finally, since our demo WebAssembly functions are written in Rust, you will also need a ",(0,a.kt)("a",{parentName:"p",href:"https://www.rust-lang.org/tools/install"},"Rust compiler"),"."),(0,a.kt)("p",null,"For the rest of the demo, fork and clone the ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/yomorun/yomo-wasmedge-tensorflow"},"source code repository"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/yomorun/yomo-wasmedge-tensorflow.git\n")),(0,a.kt)("h2",{id:"the-image-classification-function"},"The image classification function"),(0,a.kt)("p",null,"The ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/yomorun/yomo-wasmedge-tensorflow/tree/main/flow/rust_mobilenet_food"},"image classification function")," to process the YoMo image stream is written in Rust. It utilizes the WasmEdge Tensorflow API to process an input image."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust"},'#[wasmedge_bindgen]\npub fn infer(image_data: Vec<u8>) -> Result<Vec<u8>, String> {\n  let start = Instant::now();\n\n  // Load the TFLite model and its meta data (the text label for each recognized object number)\n  let model_data: &[u8] = include_bytes!("lite-model_aiy_vision_classifier_food_V1_1.tflite");\n  let labels = include_str!("aiy_food_V1_labelmap.txt");\n\n  // Pre-process the image to a format that can be used by this model\n  let flat_img = wasmedge_tensorflow_interface::load_jpg_image_to_rgb8(&image_data[..], 192, 192);\n  println!("RUST: Loaded image in ... {:?}", start.elapsed());\n\n  // Run the TFLite model using the WasmEdge Tensorflow API\n  let mut session = wasmedge_tensorflow_interface::Session::new(&model_data, wasmedge_tensorflow_interface::ModelType::TensorFlowLite);\n  session.add_input("input", &flat_img, &[1, 192, 192, 3])\n         .run();\n  let res_vec: Vec<u8> = session.get_output("MobilenetV1/Predictions/Softmax");\n\n  // Find the object index in res_vec that has the greatest probability\n  // Translate the probability into a confidence level\n  // Translate the object index into a label from the model meta data food_name\n  let mut i = 0;\n  let mut max_index: i32 = -1;\n  let mut max_value: u8 = 0;\n  while i < res_vec.len() {\n    let cur = res_vec[i];\n    if cur > max_value {\n      max_value = cur;\n      max_index = i as i32;\n    }\n    i += 1;\n  }\n  println!("RUST: index {}, prob {}", max_index, max_value);\n\n  let confidence: String;\n  if max_value > 200 {\n    confidence = "is very likely".to_string();\n  } else if max_value > 125 {\n    confidence = "is likely".to_string();\n  } else {\n    confidence = "could be".to_string();\n  }\n\n  let ret_str: String;\n  if max_value > 50 {\n    let mut label_lines = labels.lines();\n    for _i in 0..max_index {\n      label_lines.next();\n    }\n    let food_name = label_lines.next().unwrap().to_string();\n    ret_str = format!(\n      "It {} a <a href=\'https://www.google.com/search?q={}\'>{}</a> in the picture",\n      confidence, food_name, food_name\n    );\n  } else {\n    ret_str = "It does not appears to be a food item in the picture.".to_string();\n  }\n\n  println!(\n    "RUST: Finished post-processing in ... {:?}",\n    start.elapsed()\n  );\n  return Ok(ret_str.as_bytes().to_vec());\n}\n')),(0,a.kt)("p",null,"You should add ",(0,a.kt)("inlineCode",{parentName:"p"},"wasm32-wasi")," target to rust to compile this function into WebAssembly bytecode."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"rustup target add wasm32-wasi\n\ncd flow/rust_mobilenet_food\ncargo build --target wasm32-wasi --release\n# The output WASM will be target/wasm32-wasi/release/rust_mobilenet_food_lib.wasm\n\n# Copy the wasm bytecode file to the flow/ directory\ncp target/wasm32-wasi/release/rust_mobilenet_food_lib.wasm ../\n")),(0,a.kt)("p",null,"To release the best performance of WasmEdge, you should enable the AOT mode by compiling the ",(0,a.kt)("inlineCode",{parentName:"p"},".wasm")," file to the ",(0,a.kt)("inlineCode",{parentName:"p"},".so"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"wasmedgec rust_mobilenet_food_lib.wasm rust_mobilenet_food_lib.so\n")),(0,a.kt)("h2",{id:"integration-with-yomo"},"Integration with YoMo"),(0,a.kt)("p",null,"On the YoMo side, we use the WasmEdge Golang API to start and run WasmEdge VM for the image classification function. The ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/yomorun/yomo-wasmedge-tensorflow/blob/main/flow/app.go"},"app.go")," file in the source code project is as follows."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-go"},'package main\n\nimport (\n  "crypto/sha1"\n  "fmt"\n  "log"\n  "os"\n  "sync/atomic"\n\n  "github.com/second-state/WasmEdge-go/wasmedge"\n  bindgen "github.com/second-state/wasmedge-bindgen/host/go"\n  "github.com/yomorun/yomo"\n)\n\nvar (\n  counter uint64\n)\n\nconst ImageDataKey = 0x10\n\nfunc main() {\n  // Connect to Zipper service\n  sfn := yomo.NewStreamFunction("image-recognition", yomo.WithZipperAddr("localhost:9900"))\n  defer sfn.Close()\n\n  // set only monitoring data\n  sfn.SetObserveDataID(ImageDataKey)\n\n  // set handler\n  sfn.SetHandler(Handler)\n\n  // start\n  err := sfn.Connect()\n  if err != nil {\n    log.Print("\u274c Connect to zipper failure: ", err)\n    os.Exit(1)\n  }\n\n  select {}\n}\n\n// Handler process the data in the stream\nfunc Handler(img []byte) (byte, []byte) {\n  // Initialize WasmEdge\'s VM\n  vmConf, vm := initVM()\n  bg := bindgen.Instantiate(vm)\n  defer bg.Release()\n  defer vm.Release()\n  defer vmConf.Release()\n\n  // recognize the image\n  res, err := bg.Execute("infer", img)\n  if err == nil {\n    fmt.Println("GO: Run bindgen -- infer:", string(res))\n  } else {\n    fmt.Println("GO: Run bindgen -- infer FAILED")\n  }\n\n  // print logs\n  hash := genSha1(img)\n  log.Printf("\u2705 received image-%d hash %v, img_size=%d \\n", atomic.AddUint64(&counter, 1), hash, len(img))\n\n  return 0x11, nil\n}\n\n// genSha1 generate the hash value of the image\nfunc genSha1(buf []byte) string {\n  h := sha1.New()\n  h.Write(buf)\n  return fmt.Sprintf("%x", h.Sum(nil))\n}\n\n// initVM initialize WasmEdge\'s VM\nfunc initVM() (*wasmedge.Configure, *wasmedge.VM) {\n  wasmedge.SetLogErrorLevel()\n  // Set Tensorflow not to print debug info\n  os.Setenv("TF_CPP_MIN_LOG_LEVEL", "3")\n  os.Setenv("TF_CPP_MIN_VLOG_LEVEL", "3")\n\n  // Create configure\n  vmConf := wasmedge.NewConfigure(wasmedge.WASI)\n\n  // Create VM with configure\n  vm := wasmedge.NewVMWithConfig(vmConf)\n\n  // Init WASI\n  var wasi = vm.GetImportObject(wasmedge.WASI)\n  wasi.InitWasi(\n    os.Args[1:],     // The args\n    os.Environ(),    // The envs\n    []string{".:."}, // The mapping directories\n  )\n\n  // Register WasmEdge-tensorflow and WasmEdge-image\n  var tfobj = wasmedge.NewTensorflowImportObject()\n  var tfliteobj = wasmedge.NewTensorflowLiteImportObject()\n  vm.RegisterImport(tfobj)\n  vm.RegisterImport(tfliteobj)\n  var imgobj = wasmedge.NewImageImportObject()\n  vm.RegisterImport(imgobj)\n\n  // Instantiate wasm\n  vm.LoadWasmFile("rust_mobilenet_food_lib.so")\n  vm.Validate()\n\n  return vmConf, vm\n}\n')),(0,a.kt)("h2",{id:"in-action"},"In action"),(0,a.kt)("p",null,"Finally, we can start YoMo and see the entire data processing pipeline in action. Start the YoMo CLI application from the project folder. The ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/yomorun/yomo-wasmedge-tensorflow/blob/main/zipper/workflow.yaml"},"yaml file")," defines port YoMo should listen on and the workflow handler to trigger for incoming data.  Note that the flow name ",(0,a.kt)("inlineCode",{parentName:"p"},"image-recognition")," matches the name in the aforementioned data handler ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/yomorun/yomo-wasmedge-tensorflow/blob/main/flow/app.go"},"app.go"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"yomo serve -c ./zipper/workflow.yaml\n")),(0,a.kt)("p",null,"Start the handler function by running the aforementioned ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/yomorun/yomo-wasmedge-tensorflow/blob/main/flow/app.go"},"app.go")," program."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'cd flow\ngo run --tags "tensorflow image" app.go\n')),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/yomorun/yomo-wasmedge-tensorflow/blob/main/source/main.go"},"Start a simulated data source")," by sending a video to YoMo. The video is a series of image frames. The WasmEdge function in ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/yomorun/yomo-wasmedge-tensorflow/blob/main/flow/app.go"},"app.go")," will be invoked against every image frame in the video."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"# Download a video file\nwget -P source 'https://github.com/yomorun/yomo-wasmedge-tensorflow/releases/download/v0.1.0/hot-dog.mp4'\n\n# Stream the video to YoMo\ngo run ./source/main.go ./source/hot-dog.mp4\n")),(0,a.kt)("p",null,"You can see the output from the WasmEdge handler function in the console. It prints the names of the objects detected in each image frame in the video."),(0,a.kt)("h2",{id:"whats-next"},"What's next"),(0,a.kt)("p",null,"In this article, we have seen how to use the WasmEdge Tensorflow API and Golang SDK in YoMo framework to process an image stream in near real-time."),(0,a.kt)("p",null,"In collaboration with YoMo, we will soon deploy WasmEdge in production in smart factories for a variety of assembly line tasks. WasmEdge is the software runtime for edge computing!"))}c.isMDXComponent=!0}}]);